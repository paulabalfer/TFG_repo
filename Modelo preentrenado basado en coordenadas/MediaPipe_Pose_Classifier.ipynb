{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "948e4523",
   "metadata": {},
   "source": [
    "# MediaPipe Pose Classification for Artistic Swimming\n",
    "\n",
    "Sistema de clasificación de posiciones de natación artística utilizando MediaPipe para extraer keypoints de las partes del cuerpo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb380c5d",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d055eec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, ConfusionMatrixDisplay\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Librerías importadas correctamente\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "704ec251",
   "metadata": {},
   "source": [
    "## 2. Define Dataset Paths and Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0086dcc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rutas base\n",
    "DATASET_ROOT = Path('../Data/Augmented')\n",
    "MODEL_SAVE_PATH = Path('./pose_classifier_model.pkl')\n",
    "SCALER_SAVE_PATH = Path('./pose_classifier_scaler.pkl')\n",
    "ENCODER_SAVE_PATH = Path('./label_encoder.pkl')\n",
    "RESULTS_SAVE_PATH = Path('./classification_results.pkl')\n",
    "\n",
    "# Clases (nombres de carpetas)\n",
    "CLASSES = [\n",
    "    'Bent Knee Surface Arch Position',\n",
    "    'Bent Knee Vertical',\n",
    "    'Double Leg Vertical',\n",
    "    'Fishtail',\n",
    "    'Knight'\n",
    "]\n",
    "\n",
    "NUM_CLASSES = len(CLASSES)\n",
    "RANDOM_SEED = 42\n",
    "TEST_SIZE = 0.2\n",
    "IMG_SIZE = (640, 480)\n",
    "\n",
    "print(f\"Clases detectadas: {CLASSES}\")\n",
    "print(f\"Número de clases: {NUM_CLASSES}\")\n",
    "print(f\"Ruta dataset: {DATASET_ROOT.resolve()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbee0274",
   "metadata": {},
   "source": [
    "## 3. Load Image File Paths and Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5555ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset_paths(root_dir: Path, classes: list) -> tuple:\n",
    "    \"\"\"\n",
    "    Carga las rutas de las imágenes y sus labels desde el directorio de dataset.\n",
    "    \n",
    "    Args:\n",
    "        root_dir: Ruta raíz del dataset\n",
    "        classes: Lista de nombres de clases (carpetas)\n",
    "    \n",
    "    Returns:\n",
    "        Tupla (image_paths, labels)\n",
    "    \"\"\"\n",
    "    image_paths = []\n",
    "    labels = []\n",
    "    \n",
    "    for class_name in classes:\n",
    "        class_dir = root_dir / class_name\n",
    "        \n",
    "        if not class_dir.exists():\n",
    "            print(f\"Advertencia: No se encontró carpeta {class_name}\")\n",
    "            continue\n",
    "        \n",
    "        # Buscar todas las imágenes en la carpeta\n",
    "        image_files = list(class_dir.glob('*.jpg')) + list(class_dir.glob('*.jpeg')) + list(class_dir.glob('*.png'))\n",
    "        \n",
    "        print(f\"Clase '{class_name}': {len(image_files)} imágenes\")\n",
    "        \n",
    "        for img_path in image_files:\n",
    "            image_paths.append(str(img_path))\n",
    "            labels.append(class_name)\n",
    "    \n",
    "    print(f\"\\nTotal de imágenes cargadas: {len(image_paths)}\")\n",
    "    return image_paths, labels\n",
    "\n",
    "# Cargar rutas y labels\n",
    "image_paths, labels = load_dataset_paths(DATASET_ROOT, CLASSES)\n",
    "\n",
    "# Crear DataFrame\n",
    "df_dataset = pd.DataFrame({'image_path': image_paths, 'label': labels})\n",
    "print(\"\\nDistribución de clases:\")\n",
    "print(df_dataset['label'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13224b41",
   "metadata": {},
   "source": [
    "## 4. Preprocess Images and Extract MediaPipe Landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faddb1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializar MediaPipe Pose\n",
    "mp_pose = mp.solutions.pose\n",
    "pose = mp_pose.Pose(\n",
    "    static_image_mode=True,\n",
    "    model_complexity=2,  # 0=lite, 1=full, 2=heavy (más preciso pero lento)\n",
    "    smooth_landmarks=True\n",
    ")\n",
    "\n",
    "print(\"MediaPipe Pose inicializado\")\n",
    "print(f\"Número de landmarks: {mp_pose.PoseLandmark.__dict__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23771822",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_pose_landmarks(image_path: str, pose_detector) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Extrae los landmarks de pose de una imagen usando MediaPipe.\n",
    "    \n",
    "    Args:\n",
    "        image_path: Ruta a la imagen\n",
    "        pose_detector: Detector de pose inicializado de MediaPipe\n",
    "    \n",
    "    Returns:\n",
    "        Array de landmarks (x, y, z, visibility) aplanado, o None si no se detecta\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Leer imagen\n",
    "        image = cv2.imread(image_path)\n",
    "        if image is None:\n",
    "            return None\n",
    "        \n",
    "        # Convertir BGR a RGB\n",
    "        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Detectar pose\n",
    "        results = pose_detector.process(image_rgb)\n",
    "        \n",
    "        if results.pose_landmarks is None:\n",
    "            return None\n",
    "        \n",
    "        # Extraer coordenadas de landmarks (33 landmarks)\n",
    "        landmarks = []\n",
    "        for landmark in results.pose_landmarks.landmark:\n",
    "            landmarks.extend([landmark.x, landmark.y, landmark.z, landmark.visibility])\n",
    "        \n",
    "        return np.array(landmarks, dtype=np.float32)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error procesando {image_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "print(\"Función de extracción de landmarks definida\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a342bfa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_geometric_features(landmarks: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Extrae características geométricas relevantes de los landmarks para natación artística.\n",
    "    Cálculo de distancias y ángulos entre articulaciones clave.\n",
    "    \n",
    "    Args:\n",
    "        landmarks: Array de landmarks (132 elementos = 33 landmarks * 4 valores)\n",
    "    \n",
    "    Returns:\n",
    "        Array de características geométricas\n",
    "    \"\"\"\n",
    "    if landmarks is None or len(landmarks) == 0:\n",
    "        return None\n",
    "    \n",
    "    # Remodelar landmarks: 33 puntos con (x, y, z, visibility)\n",
    "    lm = landmarks.reshape(33, 4)\n",
    "    \n",
    "    features = []\n",
    "    \n",
    "    # Índices de articulaciones importantes para natación artística\n",
    "    # MediaPipe Pose landmarks:\n",
    "    # 0=nose, 11=l_shoulder, 12=r_shoulder, 23=l_hip, 24=r_hip, 25=l_knee, 26=r_knee,\n",
    "    # 27=l_ankle, 28=r_ankle, 29=l_heel, 30=l_foot_index, 31=r_heel, 32=r_foot_index\n",
    "    \n",
    "    try:\n",
    "        # 1. Distancia entre hombros\n",
    "        d_shoulders = np.linalg.norm(lm[11, :3] - lm[12, :3])\n",
    "        features.append(d_shoulders)\n",
    "        \n",
    "        # 2. Distancia entre caderas\n",
    "        d_hips = np.linalg.norm(lm[23, :3] - lm[24, :3])\n",
    "        features.append(d_hips)\n",
    "        \n",
    "        # 3. Distancia cabeza-cadera (extensión vertical)\n",
    "        d_head_hip_left = np.linalg.norm(lm[0, :3] - lm[23, :3])\n",
    "        d_head_hip_right = np.linalg.norm(lm[0, :3] - lm[24, :3])\n",
    "        features.append(max(d_head_hip_left, d_head_hip_right))\n",
    "        \n",
    "        # 4. Distancia rodilla-cadera (indicador de flexión)\n",
    "        d_knee_hip_left = np.linalg.norm(lm[25, :3] - lm[23, :3])\n",
    "        d_knee_hip_right = np.linalg.norm(lm[26, :3] - lm[24, :3])\n",
    "        features.append(d_knee_hip_left)\n",
    "        features.append(d_knee_hip_right)\n",
    "        \n",
    "        # 5. Distancia tobillo-cadera\n",
    "        d_ankle_hip_left = np.linalg.norm(lm[27, :3] - lm[23, :3])\n",
    "        d_ankle_hip_right = np.linalg.norm(lm[28, :3] - lm[24, :3])\n",
    "        features.append(d_ankle_hip_left)\n",
    "        features.append(d_ankle_hip_right)\n",
    "        \n",
    "        # 6. Relación de altura: cadera a tobillo / hombro a cadera\n",
    "        h_shoulder_hip = np.linalg.norm(lm[11, :3] - lm[23, :3])\n",
    "        h_hip_ankle_left = np.linalg.norm(lm[23, :3] - lm[27, :3])\n",
    "        h_hip_ankle_right = np.linalg.norm(lm[24, :3] - lm[28, :3])\n",
    "        features.append(h_hip_ankle_left / (h_shoulder_hip + 1e-6))\n",
    "        features.append(h_hip_ankle_right / (h_shoulder_hip + 1e-6))\n",
    "        \n",
    "        # 7. Ángulo hombro-cadera-rodilla (flexión de pierna)\n",
    "        def angle_3points(p1, p2, p3):\n",
    "            \"\"\"Calcula el ángulo en p2 formado por p1-p2-p3\"\"\"\n",
    "            v1 = p1 - p2\n",
    "            v2 = p3 - p2\n",
    "            cos_angle = np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2) + 1e-6)\n",
    "            return np.arccos(np.clip(cos_angle, -1, 1))\n",
    "        \n",
    "        angle_left_leg = angle_3points(lm[23, :3], lm[25, :3], lm[27, :3])\n",
    "        angle_right_leg = angle_3points(lm[24, :3], lm[26, :3], lm[28, :3])\n",
    "        features.append(angle_left_leg)\n",
    "        features.append(angle_right_leg)\n",
    "        \n",
    "        # 8. Ángulo cadera-hombro (inclinación del torso)\n",
    "        angle_torso = angle_3points(lm[23, :3], lm[11, :3], lm[0, :3])\n",
    "        features.append(angle_torso)\n",
    "        \n",
    "        # 9. Coordenadas Y (profundidad): indicador de inmersión\n",
    "        features.append(np.mean(lm[:, 1]))  # Y promedio de todos los puntos\n",
    "        \n",
    "        # 10. Coordenadas Z (profundidad en 3D)\n",
    "        features.append(np.mean(lm[:, 2]))  # Z promedio\n",
    "        \n",
    "        # 11. Diferencia de altura entre hombros\n",
    "        d_shoulder_y = abs(lm[11, 1] - lm[12, 1])\n",
    "        features.append(d_shoulder_y)\n",
    "        \n",
    "        # 12. Diferencia de altura entre caderas\n",
    "        d_hip_y = abs(lm[23, 1] - lm[24, 1])\n",
    "        features.append(d_hip_y)\n",
    "        \n",
    "        # 13. Visibilidad promedio (confianza en detección)\n",
    "        visibility_mean = np.mean(lm[:, 3])\n",
    "        features.append(visibility_mean)\n",
    "        \n",
    "        return np.array(features, dtype=np.float32)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error extrayendo características: {e}\")\n",
    "        return None\n",
    "\n",
    "print(\"Función de extracción de características geométricas definida\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61938f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Procesar todas las imágenes y extraer landmarks\n",
    "features_list = []\n",
    "labels_valid = []\n",
    "failed_images = []\n",
    "\n",
    "print(f\"Procesando {len(df_dataset)} imágenes...\\n\")\n",
    "\n",
    "for idx, row in tqdm(df_dataset.iterrows(), total=len(df_dataset)):\n",
    "    image_path = row['image_path']\n",
    "    label = row['label']\n",
    "    \n",
    "    # Extraer landmarks\n",
    "    landmarks = extract_pose_landmarks(image_path, pose)\n",
    "    \n",
    "    if landmarks is None:\n",
    "        failed_images.append(image_path)\n",
    "        continue\n",
    "    \n",
    "    # Extraer características geométricas\n",
    "    features = extract_geometric_features(landmarks)\n",
    "    \n",
    "    if features is not None:\n",
    "        features_list.append(features)\n",
    "        labels_valid.append(label)\n",
    "\n",
    "print(f\"\\nProcesamiento completado\")\n",
    "print(f\"Imágenes procesadas exitosamente: {len(features_list)}\")\n",
    "print(f\"Imágenes sin detección de pose: {len(failed_images)}\")\n",
    "\n",
    "if failed_images:\n",
    "    print(f\"\\nPrimeras 5 imágenes sin detección:\")\n",
    "    for img in failed_images[:5]:\n",
    "        print(f\"  - {img}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f31b9179",
   "metadata": {},
   "source": [
    "## 5. Create Feature and Label Arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9a25fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir a arrays numpy\n",
    "X = np.array(features_list, dtype=np.float32)\n",
    "y_raw = np.array(labels_valid)\n",
    "\n",
    "# Codificar etiquetas numéricamente\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y_raw)\n",
    "\n",
    "print(f\"Forma del conjunto de features: {X.shape}\")\n",
    "print(f\"Número de feature por muestra: {X.shape[1]}\")\n",
    "print(f\"\\nClases codificadas:\")\n",
    "for i, class_name in enumerate(le.classes_):\n",
    "    count = np.sum(y == i)\n",
    "    print(f\"  {class_name}: {i} (n={count})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e0faeb",
   "metadata": {},
   "source": [
    "## 6. Split Data into Training and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ff7190",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir en entrenamiento y test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=TEST_SIZE,\n",
    "    stratify=y,\n",
    "    random_state=RANDOM_SEED\n",
    ")\n",
    "\n",
    "# Normalizar features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f\"Conjunto de entrenamiento: {X_train_scaled.shape}\")\n",
    "print(f\"Conjunto de test: {X_test_scaled.shape}\")\n",
    "print(f\"\\nDistribución en entrenamiento:\")\n",
    "for i, class_name in enumerate(le.classes_):\n",
    "    count = np.sum(y_train == i)\n",
    "    print(f\"  {class_name}: {count}\")\n",
    "print(f\"\\nDistribución en test:\")\n",
    "for i, class_name in enumerate(le.classes_):\n",
    "    count = np.sum(y_test == i)\n",
    "    print(f\"  {class_name}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c477a7",
   "metadata": {},
   "source": [
    "## 7. Train a Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5707aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar Random Forest Classifier\n",
    "print(\"Entrenando Random Forest Classifier...\")\n",
    "clf_rf = RandomForestClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=20,\n",
    "    min_samples_split=5,\n",
    "    min_samples_leaf=2,\n",
    "    random_state=RANDOM_SEED,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "clf_rf.fit(X_train_scaled, y_train)\n",
    "print(\"✓ Random Forest entrenado\")\n",
    "\n",
    "# Entrenar SVM como modelo alternativo\n",
    "print(\"\\nEntrenando Support Vector Machine...\")\n",
    "clf_svm = SVC(\n",
    "    kernel='rbf',\n",
    "    C=10.0,\n",
    "    gamma='scale',\n",
    "    probability=True,\n",
    "    random_state=RANDOM_SEED,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "clf_svm.fit(X_train_scaled, y_train)\n",
    "print(\"✓ SVM entrenado\")\n",
    "\n",
    "# Usar Random Forest como modelo principal\n",
    "clf = clf_rf\n",
    "print(\"\\nModelo principal: Random Forest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b42c23",
   "metadata": {},
   "source": [
    "## 8. Evaluate Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfffec32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicciones\n",
    "y_pred_train = clf.predict(X_train_scaled)\n",
    "y_pred_test = clf.predict(X_test_scaled)\n",
    "\n",
    "# Cálculo de métricas\n",
    "train_accuracy = accuracy_score(y_train, y_pred_train)\n",
    "test_accuracy = accuracy_score(y_test, y_pred_test)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"RESULTADOS DE EVALUACIÓN\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nAccuracy en entrenamiento: {train_accuracy:.4f}\")\n",
    "print(f\"Accuracy en test: {test_accuracy:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"REPORTE DE CLASIFICACIÓN (Test Set)\")\n",
    "print(\"=\"*60)\n",
    "print(classification_report(y_test, y_pred_test, target_names=le.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9d8696",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matriz de confusión\n",
    "cm = confusion_matrix(y_test, y_pred_test)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=le.classes_)\n",
    "disp.plot(cmap='Blues', values_format='d', xticks_rotation='vertical')\n",
    "plt.title('Matriz de Confusión - Test Set')\n",
    "plt.tight_layout()\n",
    "plt.savefig('confusion_matrix.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Matriz de confusión guardada como 'confusion_matrix.png'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ef8d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importancia de features (Solo para Random Forest)\n",
    "if hasattr(clf, 'feature_importances_'):\n",
    "    feature_importance = clf.feature_importances_\n",
    "    \n",
    "    # Feature names\n",
    "    feature_names = [\n",
    "        'Shoulder Distance', 'Hip Distance', 'Head-Hip Distance',\n",
    "        'Knee-Hip Left', 'Knee-Hip Right',\n",
    "        'Ankle-Hip Left', 'Ankle-Hip Right',\n",
    "        'Hip-Ankle Ratio Left', 'Hip-Ankle Ratio Right',\n",
    "        'Leg Angle Left', 'Leg Angle Right', 'Torso Angle',\n",
    "        'Mean Y', 'Mean Z', 'Shoulder Y Diff', 'Hip Y Diff', 'Visibility Mean'\n",
    "    ]\n",
    "    \n",
    "    # Top 10 features\n",
    "    top_indices = np.argsort(feature_importance)[-10:][::-1]\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    ax.barh(range(10), feature_importance[top_indices])\n",
    "    ax.set_yticks(range(10))\n",
    "    ax.set_yticklabels([feature_names[i] if i < len(feature_names) else f'Feature {i}' for i in top_indices])\n",
    "    ax.set_xlabel('Importancia')\n",
    "    ax.set_title('Top 10 Features más importantes')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('feature_importance.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"Gráfico de importancia de features guardado como 'feature_importance.png'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed737766",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicciones en ejemplos individuales\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"EJEMPLOS DE PREDICCIONES EN TEST SET\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Mostrar 10 ejemplos aleatorios\n",
    "sample_indices = np.random.choice(len(y_test), size=min(10, len(y_test)), replace=False)\n",
    "\n",
    "for idx_in_sample, idx_in_test in enumerate(sample_indices, 1):\n",
    "    actual = le.classes_[y_test[idx_in_test]]\n",
    "    predicted = le.classes_[y_pred_test[idx_in_test]]\n",
    "    proba = clf.predict_proba(X_test_scaled[idx_in_test:idx_in_test+1])[0]\n",
    "    confidence = proba.max()\n",
    "    match = \"✓\" if actual == predicted else \"✗\"\n",
    "    \n",
    "    print(f\"\\n{idx_in_sample}. {match}\")\n",
    "    print(f\"   Actual: {actual}\")\n",
    "    print(f\"   Predicción: {predicted} (confianza: {confidence:.2%})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc2fb341",
   "metadata": {},
   "source": [
    "## 9. Save Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8da9670",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar el modelo\n",
    "joblib.dump(clf, MODEL_SAVE_PATH)\n",
    "print(f\"✓ Modelo guardado en: {MODEL_SAVE_PATH.resolve()}\")\n",
    "\n",
    "# Guardar el scaler\n",
    "joblib.dump(scaler, SCALER_SAVE_PATH)\n",
    "print(f\"✓ Scaler guardado en: {SCALER_SAVE_PATH.resolve()}\")\n",
    "\n",
    "# Guardar el encoder\n",
    "joblib.dump(le, ENCODER_SAVE_PATH)\n",
    "print(f\"✓ Label Encoder guardado en: {ENCODER_SAVE_PATH.resolve()}\")\n",
    "\n",
    "# Guardar resultados\n",
    "results = {\n",
    "    'train_accuracy': float(train_accuracy),\n",
    "    'test_accuracy': float(test_accuracy),\n",
    "    'confusion_matrix': cm.tolist(),\n",
    "    'classes': le.classes_.tolist(),\n",
    "    'num_features': X.shape[1],\n",
    "    'num_train_samples': len(X_train),\n",
    "    'num_test_samples': len(X_test),\n",
    "    'total_samples': len(X)\n",
    "}\n",
    "\n",
    "joblib.dump(results, RESULTS_SAVE_PATH)\n",
    "print(f\"✓ Resultados guardados en: {RESULTS_SAVE_PATH.resolve()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c5ee66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un resumen final\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"RESUMEN FINAL DEL MODELO\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nModelo: Random Forest Classifier\")\n",
    "print(f\"Clases: {', '.join(le.classes_)}\")\n",
    "print(f\"\\nDatos:\")\n",
    "print(f\"  - Total de muestras: {len(X)}\")\n",
    "print(f\"  - Muestras de entrenamiento: {len(X_train)}\")\n",
    "print(f\"  - Muestras de test: {len(X_test)}\")\n",
    "print(f\"  - Número de features: {X.shape[1]}\")\n",
    "print(f\"\\nRendimiento:\")\n",
    "print(f\"  - Accuracy entrenamiento: {train_accuracy:.4f}\")\n",
    "print(f\"  - Accuracy test: {test_accuracy:.4f}\")\n",
    "print(f\"\\nArchivos generados:\")\n",
    "print(f\"  - Modelo: {MODEL_SAVE_PATH.name}\")\n",
    "print(f\"  - Scaler: {SCALER_SAVE_PATH.name}\")\n",
    "print(f\"  - Encoder: {ENCODER_SAVE_PATH.name}\")\n",
    "print(f\"  - Resultados: {RESULTS_SAVE_PATH.name}\")\n",
    "print(f\"  - Matriz de confusión: confusion_matrix.png\")\n",
    "print(f\"  - Importancia de features: feature_importance.png\")\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
